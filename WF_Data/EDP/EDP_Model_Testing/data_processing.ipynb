{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import shutil\n",
    "import pickle\n",
    "import torch\n",
    "from xlsx2csv import Xlsx2csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_save_edp_data(): \n",
    "    # Download the EDP data\n",
    "    print(\"\\n Downloading EDP data\")\n",
    "    url_EDP_2016 = r\"https://www.edp.com/sites/default/files/2023-04/Wind-Turbine-SCADA-signals-2016.xlsx\"\n",
    "    url_EDP_2017 = r\"https://www.edp.com/sites/default/files/2023-04/Wind-Turbine-SCADA-signals-2017_0.xlsx\"\n",
    "\n",
    "    r_EDP_2016 = requests.get(url_EDP_2016, allow_redirects=True)\n",
    "    open(r'.temp/EDP_2016.xlsx', 'wb').write(r_EDP_2016.content)\n",
    "    r_EDP_2017 = requests.get(url_EDP_2017, allow_redirects=True)\n",
    "    open(r'.temp/EDP_2017.xlsx', 'wb').write(r_EDP_2017.content)\n",
    "\n",
    "\n",
    "    print(\"Convert 2016\")\n",
    "    Xlsx2csv(r'.temp/EDP_2016.xlsx', outputencoding=\"utf-8\").convert(r'.temp/EDP_2016.csv')\n",
    "    print(\"Convert 2017\")\n",
    "    Xlsx2csv(r'.temp/EDP_2017.xlsx', outputencoding=\"utf-8\").convert(r'.temp/EDP_2017.csv')\n",
    "\n",
    "    df_2016 = pd.read_csv(\".temp/EDP_2016.csv\", parse_dates= [\"Timestamp\"])\n",
    "    df_2017 = pd.read_csv(\".temp/EDP_2017.csv\", parse_dates= [\"Timestamp\"])\n",
    "\n",
    "    df = pd.concat([df_2016, df_2017])\n",
    "    df[\"Timestamp\"].unique(), df_2016[\"Timestamp\"].unique(),df_2017[\"Timestamp\"].unique()\n",
    "\n",
    "    df = pd.concat([df_2016, df_2017])\n",
    "    for t in df[\"Turbine_ID\"].unique():\n",
    "        d = copy.deepcopy(df[df[\"Turbine_ID\"] == t])\n",
    "        tnum = t[-2:]\n",
    "        print(f\"Saving EDP wind turbine WT_{tnum}\")\n",
    "        d.to_csv(f\"EDP/WT_{tnum}.csv\", index=False)\n",
    "\n",
    "    shutil.rmtree('.temp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fault_logs(): \n",
    "    # Download the EDP data\n",
    "    print(\"\\n Downloading EDP data\")\n",
    "    url_EDP_faults_2016 = r\"https://www.edp.com/sites/default/files/2023-04/Historical-Failure-Logbook-2016.xlsx\"\n",
    "    url_EDP_faults_2017 = r\"https://www.edp.com/sites/default/files/2023-04/opendata-wind-failures-2017.xlsx\"\n",
    "\n",
    "    r_EDP_2016 = requests.get(url_EDP_faults_2016, allow_redirects=True)\n",
    "    open(r'.temp/EDP_faults_2016.xlsx', 'wb').write(r_EDP_2016.content)\n",
    "    r_EDP_2017 = requests.get(url_EDP_faults_2017, allow_redirects=True)\n",
    "    open(r'.temp/EDP_faults_2017.xlsx', 'wb').write(r_EDP_2017.content)\n",
    "\n",
    "    print(\"Convert Faults 2016\")\n",
    "    Xlsx2csv(r'.temp/EDP_faults_2016.xlsx', outputencoding=\"utf-8\").convert(r'.temp/EDP_faults_2016.csv')\n",
    "    print(\"Convert Faults 2017\")\n",
    "    Xlsx2csv(r'.temp/EDP_faults_2017.xlsx', outputencoding=\"utf-8\").convert(r'.temp/EDP_faults_2017.csv')\n",
    "\n",
    "    df_2016 = pd.read_csv(\".temp/EDP_faults_2016.csv\", parse_dates= [\"Timestamp\"])\n",
    "    df_2017 = pd.read_csv(\".temp/EDP_faults_2017.csv\", parse_dates= [\"Timestamp\"])\n",
    "\n",
    "    df = pd.concat([df_2016, df_2017])\n",
    "    df[\"Timestamp\"].unique(), df_2016[\"Timestamp\"].unique(),df_2017[\"Timestamp\"].unique()\n",
    "\n",
    "    df = pd.concat([df_2016, df_2017])\n",
    "    df.drop(columns=['Component', 'Remarks'], inplace=True)\n",
    "    for t in df[\"Turbine_ID\"].unique():\n",
    "        d = copy.deepcopy(df[df[\"Turbine_ID\"] == t])\n",
    "        tnum = t[-2:]\n",
    "        print(f\"Saving EDP wind turbine WT_{tnum}\")\n",
    "        d.to_csv(f\"fault_logs/WT_{tnum}.csv\", index=False)\n",
    "\n",
    "    shutil.rmtree('.temp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs()\n",
    "    paths = [\".temp\", \"data_normalisation\", \"data_prep\", \"EDP\", \"EDP_filtered\", \"fault_logs\"]\n",
    "    for path in paths:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Downloading EDP data\n",
      "Convert Faults 2016\n",
      "Convert Faults 2017\n",
      "Saving EDP wind turbine WT_01\n",
      "Saving EDP wind turbine WT_06\n",
      "Saving EDP wind turbine WT_07\n",
      "Saving EDP wind turbine WT_09\n",
      "Saving EDP wind turbine WT_11\n"
     ]
    }
   ],
   "source": [
    "create_dirs()\n",
    "get_and_save_edp_data()\n",
    "create_dirs()\n",
    "get_fault_logs()\n",
    "edp_path = os.path.abspath(\"EDP\")\n",
    "if os.path.exists(edp_path): \n",
    "    for path in os.listdir(edp_path): \n",
    "        df = pd.read_csv(os.path.join(edp_path, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Processing the data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n Processing the data\\n\")\n",
    "# EDP\n",
    "cols_edp = [\n",
    "    \"Timestamp\", \n",
    "    \"Wind_speed\",\n",
    "    \"Wind_speed_std\",\n",
    "    \"Wind_rel_dir\",\n",
    "    \"Amb_temp\",\n",
    "    \"Gen_speed\", \n",
    "    \"Gen_speed_std\",\n",
    "    \"Rotor_speed\", \n",
    "    \"Rotor_speed_std\",\n",
    "    \"Blade_pitch\",\n",
    "    \"Blade_pitch_std\",\n",
    "    \"Gen_phase_temp_1\",\n",
    "    \"Gen_phase_temp_2\",\n",
    "    \"Gen_phase_temp_3\",\n",
    "    \"Transf_temp_p1\",\n",
    "    \"Transf_temp_p2\",\n",
    "    \"Transf_temp_p3\",\n",
    "    \"Gen_bearing_temp_1\", \n",
    "    \"Gen_bearing_temp_2\", \n",
    "    \"Hyd_oil_temp\",\n",
    "    \"Gear_oil_temp\",\n",
    "    \"Gear_bear_temp\", \n",
    "    \"Nacelle_position\",\n",
    "    \"Power\"\n",
    "]\n",
    "rename_edp = {\n",
    "    \"Timestamp\": \"Timestamp\", \n",
    "    \n",
    "    # Enviromental Statistics\n",
    "    \"Amb_WindSpeed_Avg\": \"Wind_speed\",\n",
    "    \"Amb_WindSpeed_Std\": \"Wind_speed_std\",\n",
    "    \"Amb_WindDir_Relative_Avg\": \"Wind_rel_dir\",\n",
    "    \"Amb_Temp_Avg\": \"Amb_temp\",\n",
    "\n",
    "    # Affects energy conversion efficiency\n",
    "        # Generator RPM Statistics\n",
    "    \"Gen_RPM_Avg\": \"Gen_speed\", \n",
    "    \"Gen_RPM_Std\": \"Gen_speed_std\",\n",
    "        # Rotor Statistics\n",
    "    \"Rtr_RPM_Avg\": \"Rotor_speed\", \n",
    "    \"Rtr_RPM_Std\": \"Rotor_speed_std\",\n",
    "\n",
    "    # Blade Pitch Angle, Optimizes wind capture\n",
    "    \"Blds_PitchAngle_Avg\" : \"Blade_pitch\",\n",
    "    \"Blds_PitchAngle_Std\" : \"Blade_pitch_std\",\n",
    "\n",
    "    # Impacts efficiency & potential failures\n",
    "        # Generator average temperatures of the stator windings (the stationary part of the generator) for each phase\n",
    "        # Indicates power generation health, winding issues, and cooling efficiency inside the generator\n",
    "    \"Gen_Phase1_Temp_Avg\" : \"Gen_phase_temp_1\",\n",
    "    \"Gen_Phase2_Temp_Avg\" : \"Gen_phase_temp_2\",\n",
    "    \"Gen_Phase3_Temp_Avg\" : \"Gen_phase_temp_3\",\n",
    "        # Transformer phase temperatures\t\n",
    "        # power transmission efficiency, grid loading issues, and transformer overheating risks.\n",
    "    \"HVTrafo_Phase1_Temp_Avg\": \"Transf_temp_p1\",\n",
    "    \"HVTrafo_Phase2_Temp_Avg\": \"Transf_temp_p2\",\n",
    "    \"HVTrafo_Phase3_Temp_Avg\": \"Transf_temp_p3\",\n",
    "\n",
    "    # Temperatures that might indicate fault/high stress\n",
    "    # Generator Bearing Temperature Statisitcs TODO: always 2 generator bearings?\n",
    "    \"Gen_Bear_Temp_Avg\": \"Gen_bearing_temp_1\", \n",
    "    \"Gen_Bear2_Temp_Avg\": \"Gen_bearing_temp_2\", \n",
    "        # Hydraulic oil temperature\n",
    "    \"Hyd_Oil_Temp_Avg\": \"Hyd_oil_temp\",\n",
    "        # Gearbox Statistics\n",
    "    \"Gear_Oil_Temp_Avg\" : \"Gear_oil_temp\",\n",
    "    \"Gear_Bear_Temp_Avg\": \"Gear_bear_temp\", \n",
    "\n",
    "    # Nacelle Direction - should align with wind realtive direction ... not doing so = poor performance? \n",
    "    \"Nac_Direction_Avg\": \"Nacelle_position\",\n",
    "\n",
    "    # Power (have it by generator, but excluding bc feature would be too correlated with target feature ... total active power)\n",
    "    \"Prod_LatestAvg_TotActPwr\": \"Power\",\n",
    "}\n",
    "list_names_edp = [\"WT_01\", \"WT_06\", \"WT_07\", \"WT_11\"]\n",
    "DATA_PATH_EDP = r\"EDP\"\n",
    "FAULT_LOG_PATH_EDP = r\"fault_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_farm:\n",
    "    def __init__(\n",
    "            self, \n",
    "            name, \n",
    "            cols, \n",
    "            list_turbine_name, \n",
    "            DATA_PATH, \n",
    "            FAULT_LOG_PATH,\n",
    "            rename\n",
    "        ):\n",
    "        self.name = name\n",
    "        self.columns = cols\n",
    "        self.list_turbine_name = list_turbine_name\n",
    "        self.DATA_PATH = DATA_PATH\n",
    "        self.FAULT_LOG_PATH = FAULT_LOG_PATH\n",
    "        self.in_shift = 24*6\n",
    "        self.out_shift = 1\n",
    "        self.RESET = False\n",
    "        self.load_data_window = False\n",
    "        self.max_workers = 10  \n",
    "        self.normalized_dict = {}\n",
    "        self.normalized_circ_dict = {}\n",
    "        self.rename = rename\n",
    "        self.initialize = True\n",
    "        self.time_name = \"Timestamp\"\n",
    "        self.in_cols = [\n",
    "            \"Wind_speed\",\n",
    "            \"Wind_speed_std\",\n",
    "            \"Wind_rel_dir\",\n",
    "            \"Amb_temp\",\n",
    "            \"Gen_speed\", \n",
    "            \"Gen_speed_std\",\n",
    "            \"Rotor_speed\", \n",
    "            \"Rotor_speed_std\",\n",
    "            \"Blade_pitch\",\n",
    "            \"Blade_pitch_std\",\n",
    "            \"Gen_phase_temp_1\",\n",
    "            \"Gen_phase_temp_2\",\n",
    "            \"Gen_phase_temp_3\",\n",
    "            \"Transf_temp_p1\",\n",
    "            \"Transf_temp_p2\",\n",
    "            \"Transf_temp_p3\",\n",
    "            \"Gen_bearing_temp_1\", \n",
    "            \"Gen_bearing_temp_2\", \n",
    "            \"Hyd_oil_temp\",\n",
    "            \"Gear_oil_temp\",\n",
    "            \"Gear_bear_temp\", \n",
    "            \"Nacelle_position\",\n",
    "        ]\n",
    "        self.out_cols = [\"Power\"]\n",
    "        self.PATH = r\"data_prep\"\n",
    "\n",
    "        # Initializing or loading the turbine data\n",
    "        if self.initialize:\n",
    "            for t in self.list_turbine_name:\n",
    "                print(f\"Initializing {t}\")\n",
    "                self.initialize_data(t)\n",
    "            self.prepare_data()\n",
    "        else:\n",
    "            self.load_data()\n",
    "        \n",
    "        self.X, self.y, self.timestamps = {t : None for t in self.list_turbine_name}, {t : None for t in self.list_turbine_name}, {t : None for t in self.list_turbine_name}\n",
    "\n",
    "    def initialize_data(self, t):\n",
    "        setattr(self, t, self.load_df(f\"{t}.csv\", rename=self.rename))\n",
    "        assert \"Timestamp\" in getattr(self, t).columns, f\"Need a timestamp column\"\n",
    "        assert \"Wind_speed\" in getattr(self, t).columns, f\"Need a Wind_speed column\"\n",
    "        index = pd.to_datetime(getattr(self, t)[\"Timestamp\"]).dt.tz_convert(None) \n",
    "        getattr(self, t).set_index(index, inplace=True)\n",
    "        getattr(self, t).drop([\"Timestamp\"], axis=1, inplace=True)\n",
    "        \n",
    "    def load_df(self, file_name, rename = {}):\n",
    "        wt_df = pd.read_csv(os.path.join(self.DATA_PATH, file_name), parse_dates=[self.time_name])\n",
    "        # data cleaning, renaming\n",
    "        if len(self.rename) > 0:\n",
    "            rename = {key: rename[key] for key  in rename.keys() if key in wt_df.columns}\n",
    "            wt_df.rename(columns=self.rename, inplace=True)\n",
    "\n",
    "        wt_df[\"Timestamp\"] = pd.to_datetime(wt_df[\"Timestamp\"], utc=True)\n",
    "        f = ~wt_df[\"Timestamp\"].isnull()\n",
    "        wt_df = wt_df[f].sort_values(by = [\"Timestamp\"]).reset_index().drop([\"index\"], axis = 1) \n",
    "\n",
    "        # only keep the wanted columns (time, x and y features)\n",
    "        wt_df = wt_df[[c for c in self.columns if c in wt_df.columns]]\n",
    "\n",
    "        # Set data to NaN for fault windows\n",
    "        fault_df = pd.read_csv(os.path.join(self.FAULT_LOG_PATH, file_name), parse_dates=[self.time_name])\n",
    "\n",
    "        wt_df.set_index(\"Timestamp\", inplace=True)\n",
    "        for fault_time in fault_df['Timestamp']:\n",
    "            start_time = fault_time - pd.Timedelta(weeks=2)\n",
    "            end_time = fault_time + pd.Timedelta(days=3)\n",
    "            wt_df.loc[(wt_df.index >= start_time) & (wt_df.index <= end_time), self.in_cols] = np.nan\n",
    "            wt_df.loc[(wt_df.index >= start_time) & (wt_df.index <= end_time), self.out_cols] = np.nan\n",
    "        \n",
    "        cols_of_interest = (['Gen_speed', 'Gen_speed_std', 'Rotor_speed', 'Rotor_speed_std', 'Power'])\n",
    "        for col in cols_of_interest:\n",
    "            zero_col_with_wind = (wt_df[col] == 0) & (wt_df[\"Wind_speed\"] > 4.5)\n",
    "            if zero_col_with_wind.any():\n",
    "                print(\"Timestamps where Wind is > 4.5 but\", col, \"is 0:\")\n",
    "                print(wt_df.index[zero_col_with_wind])\n",
    "                print(\"Setting them to nan\")\n",
    "                wt_df.loc[zero_col_with_wind, self.in_cols] = np.nan\n",
    "                wt_df.loc[zero_col_with_wind, self.out_cols] = np.nan\n",
    "            else:\n",
    "                print(f\"No occurrences found for {col}.\")\n",
    "        \n",
    "        wt_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "        wt_df.to_csv(os.path.join(\"/home/ujx4ab/ondemand/dissecting_dist_inf/WF_Data/EDP/EDP_Model_Testing/EDP_filtered\", file_name))\n",
    "        \n",
    "        return wt_df \n",
    "     \n",
    "    def save_data(self,turbine = None):\n",
    "        turbine = turbine if turbine is not None else self.list_turbine_name\n",
    "        for t in turbine:\n",
    "            getattr(self, t).to_csv(os.path.join(self.PATH, f\"{self.name}_{t}.csv\")) \n",
    "    \n",
    "    def load_data(self, t = None):\n",
    "        turbine = t if t is not None else self.list_turbine_name\n",
    "        for t in turbine:\n",
    "            f=os.path.join(self.PATH, f\"{self.name}_{t}.csv\")\n",
    "            assert os.path.isfile(os.path.join(self.PATH, f\"{self.name}_{t}.csv\")), f\"File {f} does not exists\"\n",
    "            setattr(self, t, pd.read_csv(os.path.join(self.PATH, f\"{self.name}_{t}.csv\"), index_col= \"Timestamp\", parse_dates= True))\n",
    "    \n",
    "    def feature_cut(self, feature_name, min = None, max = None, min_value = \"drop\", max_value = \"drop\", turbine_name = None, verbose = False):\n",
    "        turbine = turbine_name if turbine_name is not None else self.list_turbine_name\n",
    "\n",
    "        for t in turbine:\n",
    "            assert feature_name in getattr(self, t).columns, f\"Wrong feature name: {feature_name}\"\n",
    "            n = len(getattr(self, t)[feature_name])\n",
    "            if min is not None:\n",
    "                if min_value == \"drop\":\n",
    "                    cut_offs = getattr(self, t)[getattr(self, t)[feature_name] < min].index\n",
    "                    getattr(self, t).drop(cut_offs, inplace=True)\n",
    "                else:\n",
    "                    neg_powers = getattr(self, t)[getattr(self, t)[feature_name] < min].index\n",
    "                    getattr(self, t).loc[neg_powers, feature_name] = min_value\n",
    "            if max is not None: \n",
    "                if max_value == \"drop\":\n",
    "                    cut_offs = getattr(self, t)[getattr(self, t)[feature_name] > max].index\n",
    "                    getattr(self, t).drop(cut_offs, inplace=True)\n",
    "                else:\n",
    "                    neg_powers = getattr(self, t)[getattr(self, t)[feature_name] > max].index\n",
    "                    getattr(self, t).loc[neg_powers, feature_name] = max_value \n",
    "            if verbose:\n",
    "                print(f\"Cutted {n-len(getattr(self, t)[feature_name])} element from {t} for {feature_name} in {self.name}\")\n",
    "\n",
    "    def line_cut(self, input_feature_name, output_feature_name, a, b, xmin, xmax, under = True, turbine_name = None):\n",
    "        turbine = turbine_name if turbine_name is not None else self.list_turbine_name\n",
    "        \n",
    "        for t in turbine:\n",
    "            assert input_feature_name in getattr(self, t).columns, f\"Wrong feature name: {input_feature_name}\"\n",
    "            assert output_feature_name in getattr(self, t).columns, f\"Wrong feature name: {output_feature_name}\"\n",
    "            if under:\n",
    "                f = lambda x: x[input_feature_name] <= xmin or a*x[input_feature_name] + b < x[output_feature_name] or x[input_feature_name] >= xmax\n",
    "            else:\n",
    "                f = lambda x: x[input_feature_name] <= xmin or a*x[input_feature_name] + b > x[output_feature_name] or x[input_feature_name] >= xmax\n",
    "            setattr(self, t, getattr(self, t)[getattr(self, t).apply(f, axis=1)])\n",
    "            \n",
    "    def feature_averaging(self, name, input_names):\n",
    "        for t in self.list_turbine_name:\n",
    "            assert all([name in getattr(self,t).columns for name in input_names]), f\"The input names are incorrect: {[name for name in input_names if name not in getattr(self,t).columns]}\"\n",
    "            getattr(self, t)[name] = getattr(self, t)[input_names].mean(axis= 1)\n",
    "    \n",
    "    def normalize_min_max(self, cols):\n",
    "        for t in self.list_turbine_name:\n",
    "            self.normalized_dict[t] = {c : (getattr(self, t)[c].max(), getattr(self, t)[c].min()) for c in cols}\n",
    "            for c in cols:\n",
    "                getattr(self, t)[c] = (getattr(self,t)[c] - self.normalized_dict[t][c][1])/(self.normalized_dict[t][c][0]-self.normalized_dict[t][c][1])\n",
    "\n",
    "        with open(os.path.join(r'data_normalisation', f'min_max_normalisation_{self.name}.pkl'), 'wb') as f:\n",
    "            pickle.dump(self.normalized_dict, f)\n",
    "    \n",
    "    def normalize_mean_std(self, cols):\n",
    "        for t in self.list_turbine_name:\n",
    "            self.normalized_dict[t] = {c : (getattr(self, t)[c].mean(), getattr(self, t)[c].std()) for c in cols}\n",
    "            for c in cols:\n",
    "                getattr(self, t)[c] = (getattr(self,t)[c] - self.normalized_dict[t][c][0])/(self.normalized_dict[t][c][1])\n",
    " \n",
    "        with open(os.path.join(r'data_normalisation', f'std_mean_normalisation_{self.name}.pkl'), 'wb') as f:\n",
    "            pickle.dump(self.normalized_dict, f)\n",
    "\n",
    "    def circ_embedding(self, cols):\n",
    "        # Assuming that the unit is ° (0 to 360)\n",
    "        for t in self.list_turbine_name:\n",
    "            for c in cols:\n",
    "                getattr(self, t)[f\"{c}_cos\"] = np.cos(getattr(self,t)[c]*2*np.pi/360)\n",
    "                getattr(self, t)[f\"{c}_sin\"] = np.sin(getattr(self,t)[c]*2*np.pi/360)\n",
    "\n",
    "    def drop_col(self, cols):\n",
    "        for t in self.list_turbine_name:\n",
    "            getattr(self,t).drop(columns = cols, inplace = True)\n",
    "\n",
    "    def time_filling(self, method = 'linear', interpolation_limit = 6):\n",
    "        for t in self.list_turbine_name:\n",
    "            setattr(self,t, getattr(self, t).asfreq(\"10min\"))\n",
    "            getattr(self,t).interpolate(method = method, limit=interpolation_limit, inplace = True)\n",
    "            print(getattr(self, t).shape)\n",
    "\n",
    "    def prepare_data(self): \n",
    "        if self.name == \"EDP\":\n",
    "            self.feature_averaging(\"Gen_bear_temp_avg\", [\"Gen_bearing_temp_1\", \"Gen_bearing_temp_2\"])\n",
    "            self.feature_cut(\"Wind_speed\", min=0, max= 25, min_value=0)\n",
    "            self.feature_cut(\"Power\", min=0,  min_value=0)\n",
    "            self.feature_cut(\"Rotor_speed\", min=0,  min_value=0)\n",
    "            self.feature_cut(\"Gen_speed\", min=0)\n",
    "            self.line_cut(\"Wind_speed\", \"Power\", a = 0, b= 1100, xmin = 4.2, xmax= 25)\n",
    "\n",
    "        cols = self.out_cols + self.in_cols\n",
    "\n",
    "        for t in self.list_turbine_name:\n",
    "            setattr(self, t, getattr(self, t)[~getattr(self, t).index.duplicated()])\n",
    "\n",
    "        self.drop_col([c for c in getattr(self, self.list_turbine_name[0]).columns if c not in cols])\n",
    "\n",
    "        # cols_of_interest = (['Wind_speed', 'Gen_speed', 'Gen_speed_std', \n",
    "        #                     'Rotor_speed','Rotor_speed_std', 'Power'])\n",
    "        # # Check for nonzero wind speed but zero power, and remove such rows\n",
    "        # for t in self.list_turbine_name:\n",
    "        #     turbine_df = getattr(self, t)\n",
    "        #     print(f\"before dropping {turbine_df.shape}\")\n",
    "        #     zero_rows = (turbine_df[\"Wind_speed\"] > 4.5) & (turbine_df[cols_of_interest] == 0).any(axis=1)\n",
    "        #     print(f\"Turbine {t}: Rows removed: {zero_rows.sum()}\")\n",
    "        #     setattr(self, t, turbine_df[~zero_rows])\n",
    "        #     print(zero_rows)\n",
    "        #     turbine_df = getattr(self, t)\n",
    "        #     print(f\"after1 dropping {turbine_df.shape}\")\n",
    "        \n",
    "        self.time_filling(interpolation_limit = 12)\n",
    "\n",
    "        # Normalization\n",
    "        self.normalize_min_max(cols=[c for c in cols if c not in [\"Wind_speed\", \"Amb_temp\", \"Gen_speed\", \"Rotor_speed\",\n",
    "                                                             \"Gen_phase_temp_1\", \"Gen_phase_temp_2\", \"Gen_phase_temp_3\",\n",
    "                                                             \"Transf_temp_p1\", \"Transf_temp_p2\", \"Transf_temp_p3\",\n",
    "                                                             \"Gen_bear_temp_avg\", \"Hyd_oil_temp\",\n",
    "                                                             \"Gear_oil_temp\", \"Gear_bear_temp\", \"Nacelle_position\"]])\n",
    "        self.normalize_mean_std(cols=[c for c in cols if c in [\"Wind_speed_std\", \"Gen_speed_std\", \"Rotor_speed_std\"]])\n",
    "        self.circ_embedding(cols=[c for c in cols if c in [\"Wind_rel_dir\", \"Nacelle_position, Blade_pitch\"]])\n",
    "\n",
    "        for t in self.list_turbine_name:\n",
    "            getattr(self,t).dropna(how = \"any\", inplace = True)\n",
    "            pd.to_datetime(getattr(self,t).index,errors='ignore') \n",
    "        self.save_data()\n",
    "\n",
    "    def get_window_data(self, in_shift, in_cols, out_cols, PATH = r\"data_prep\", RESET = False):\n",
    "        \n",
    "        if RESET:\n",
    "             self.make_window_data(in_shift, in_cols, out_cols, turbine = None,  PATH = PATH)\n",
    "        else:\n",
    "            turbine = [t for t in self.list_turbine_name if not (os.path.isfile(os.path.join(PATH, f\"{self.name}_{t}_X.pt\")) and \\\n",
    "                                                                 os.path.isfile(os.path.join(PATH, f\"{self.name}_{t}_y.pt\")) and \\\n",
    "                                                                 os.path.isfile(os.path.join(PATH, f\"{self.name}_{t}_timestamp.pkl\")))]\n",
    "            \n",
    "            self.make_window_data(in_shift, in_cols, out_cols, turbine= turbine, PATH= PATH)\n",
    "            \n",
    "        for t in self.list_turbine_name:\n",
    "            setattr(self, f\"{t}_X\", torch.load(os.path.join(PATH, f\"{self.name}_{t}_X.pt\")))\n",
    "            setattr(self, f\"{t}_y\", torch.load(os.path.join(PATH, f\"{self.name}_{t}_y.pt\")))\n",
    "            with open(os.path.join(PATH, f\"{self.name}_{t}_timestamp.pkl\"), 'rb') as f:\n",
    "                setattr(self, f\"{t}_timestamp\", pickle.load(f))\n",
    "\n",
    "    def make_window_data(self, in_shift, in_cols, out_cols, turbine = None, PATH = r\"data_prep\", ret = False):\n",
    "        turbine = turbine if turbine is not None else self.list_turbine_name \n",
    "        \n",
    "        for t in turbine: \n",
    "            print(f\"Preparing turbine {t}\")\n",
    "        \n",
    "            data = getattr(self,t)\n",
    "            in_data = data[in_cols].to_numpy(copy = True)\n",
    "            out_data = data[out_cols].to_numpy(copy = True)\n",
    "            \n",
    "            index = data.index\n",
    "            daterange = pd.date_range(start=index[0], end=index[-1], freq = \"10min\")\n",
    "\n",
    "            #Creating blocks of timestamps without missing values\n",
    "            blocks = [[]]\n",
    "            i = 0\n",
    "            for d in daterange:\n",
    "                if d in data.index:\n",
    "                    blocks[i].append(d)\n",
    "                elif blocks[-1] != []:\n",
    "                    blocks.append([])\n",
    "                    i+=1\n",
    "            if blocks[-1] == []:\n",
    "                blocks = blocks[:-1]\n",
    "            \n",
    "            # For each block make a dataset\n",
    "            in_datasets = []\n",
    "            out_datasets = []\n",
    "            timestamps = []\n",
    "\n",
    "            for block in blocks:\n",
    "                if len(block) > in_shift:\n",
    "                    in_window = [in_data[i: i + in_shift +1] for i in range(len(block)-in_shift)]\n",
    "                    out_window = [out_data[i+ in_shift] for i in range(len(block)-in_shift)]\n",
    "                    timestamp = [block[i+in_shift] for i in range(len(block)-in_shift)]\n",
    "                else:\n",
    "                    in_window = None\n",
    "                    out_window = None\n",
    "                    timestamp = None\n",
    "                if in_window is not None and out_window is not None and timestamp is not None:\n",
    "                    in_datasets.append(in_window)\n",
    "                    out_datasets.append(out_window)\n",
    "                    timestamps.append(timestamp)\n",
    "\n",
    "            # Concatenate the blocks\n",
    "            if len(in_datasets) > 0:\n",
    "                in_window_full = np.concatenate(in_datasets)\n",
    "                out_window_full = np.concatenate(out_datasets)\n",
    "                time = np.concatenate(timestamps)\n",
    "                X, y = torch.Tensor(in_window_full), torch.Tensor(out_window_full)\n",
    "                torch.save(X, os.path.join(PATH, f\"{self.name}_{t}_X.pt\"))\n",
    "                torch.save(y, os.path.join(PATH, f\"{self.name}_{t}_y.pt\"))\n",
    "                with open( os.path.join(PATH, f\"{self.name}_{t}_timestamp.pkl\"), \"wb\") as f:\n",
    "                    pickle.dump(time, f)\n",
    "                \n",
    "                if ret:\n",
    "                    return X,y,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing WT_01\n",
      "Timestamps where Wind is > 4.5 but Gen_speed is 0:\n",
      "DatetimeIndex(['2016-09-19 09:10:00+00:00', '2016-09-19 09:20:00+00:00',\n",
      "               '2016-09-19 09:30:00+00:00', '2016-09-19 09:40:00+00:00',\n",
      "               '2016-09-19 10:00:00+00:00', '2016-09-19 10:10:00+00:00',\n",
      "               '2016-09-19 10:30:00+00:00', '2016-09-19 10:40:00+00:00',\n",
      "               '2016-09-19 10:50:00+00:00', '2016-09-19 11:00:00+00:00',\n",
      "               '2016-09-19 11:10:00+00:00', '2016-09-19 11:20:00+00:00',\n",
      "               '2016-09-19 11:30:00+00:00', '2016-09-19 11:40:00+00:00',\n",
      "               '2016-09-19 11:50:00+00:00', '2016-09-19 12:00:00+00:00',\n",
      "               '2016-09-19 12:10:00+00:00', '2016-09-19 13:50:00+00:00',\n",
      "               '2016-09-19 15:40:00+00:00', '2016-09-19 16:00:00+00:00',\n",
      "               '2016-09-19 16:30:00+00:00', '2016-10-14 13:00:00+00:00',\n",
      "               '2016-10-14 13:20:00+00:00', '2016-10-14 13:30:00+00:00',\n",
      "               '2017-02-02 09:40:00+00:00', '2017-02-22 10:30:00+00:00',\n",
      "               '2017-02-22 10:40:00+00:00', '2017-02-22 10:50:00+00:00',\n",
      "               '2017-02-22 11:00:00+00:00', '2017-04-25 11:20:00+00:00',\n",
      "               '2017-04-25 11:30:00+00:00', '2017-04-25 11:40:00+00:00',\n",
      "               '2017-04-25 11:50:00+00:00', '2017-04-25 12:00:00+00:00',\n",
      "               '2017-04-25 12:10:00+00:00', '2017-04-25 12:20:00+00:00',\n",
      "               '2017-04-25 12:50:00+00:00', '2017-04-25 13:10:00+00:00',\n",
      "               '2017-05-10 09:50:00+00:00', '2017-05-10 10:00:00+00:00',\n",
      "               '2017-05-10 10:10:00+00:00', '2017-05-10 10:20:00+00:00',\n",
      "               '2017-05-10 10:30:00+00:00', '2017-05-10 10:40:00+00:00',\n",
      "               '2017-05-10 10:50:00+00:00', '2017-05-10 11:00:00+00:00',\n",
      "               '2017-05-10 11:10:00+00:00', '2017-05-10 11:20:00+00:00',\n",
      "               '2017-05-10 11:30:00+00:00', '2017-05-10 11:40:00+00:00',\n",
      "               '2017-05-10 11:50:00+00:00', '2017-05-10 12:00:00+00:00',\n",
      "               '2017-05-10 12:10:00+00:00', '2017-07-12 13:40:00+00:00',\n",
      "               '2017-07-12 13:50:00+00:00', '2017-07-12 14:00:00+00:00',\n",
      "               '2017-07-12 14:10:00+00:00', '2017-07-12 14:20:00+00:00',\n",
      "               '2017-07-12 14:30:00+00:00', '2017-07-12 14:40:00+00:00',\n",
      "               '2017-07-12 14:50:00+00:00', '2017-07-12 15:00:00+00:00',\n",
      "               '2017-07-12 15:10:00+00:00', '2017-07-12 15:20:00+00:00',\n",
      "               '2017-07-12 16:20:00+00:00', '2017-08-17 10:30:00+00:00',\n",
      "               '2017-08-17 10:40:00+00:00', '2017-08-17 11:40:00+00:00',\n",
      "               '2017-08-17 11:50:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='Timestamp', freq=None)\n",
      "Setting them to nan\n",
      "No occurrences found for Gen_speed_std.\n",
      "Timestamps where Wind is > 4.5 but Rotor_speed is 0:\n",
      "DatetimeIndex(['2016-02-06 05:10:00+00:00', '2016-02-22 14:40:00+00:00',\n",
      "               '2016-02-22 14:50:00+00:00', '2016-02-22 15:00:00+00:00',\n",
      "               '2016-02-24 17:50:00+00:00', '2016-02-24 18:00:00+00:00',\n",
      "               '2016-02-24 18:10:00+00:00', '2016-02-24 18:20:00+00:00',\n",
      "               '2016-02-24 18:30:00+00:00', '2016-03-27 18:30:00+00:00',\n",
      "               ...\n",
      "               '2017-10-17 11:00:00+00:00', '2017-11-02 11:40:00+00:00',\n",
      "               '2017-11-11 15:30:00+00:00', '2017-11-11 15:40:00+00:00',\n",
      "               '2017-11-11 15:50:00+00:00', '2017-11-11 16:00:00+00:00',\n",
      "               '2017-11-29 07:20:00+00:00', '2017-12-04 07:50:00+00:00',\n",
      "               '2017-12-04 08:00:00+00:00', '2017-12-07 13:30:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='Timestamp', length=1053, freq=None)\n",
      "Setting them to nan\n",
      "Timestamps where Wind is > 4.5 but Rotor_speed_std is 0:\n",
      "DatetimeIndex(['2016-01-06 00:50:00+00:00', '2016-01-06 01:00:00+00:00',\n",
      "               '2016-01-06 19:10:00+00:00', '2016-01-06 22:00:00+00:00',\n",
      "               '2016-01-14 10:40:00+00:00', '2016-01-28 22:50:00+00:00',\n",
      "               '2016-01-30 20:20:00+00:00', '2016-02-09 07:00:00+00:00',\n",
      "               '2016-02-09 07:10:00+00:00', '2016-02-09 07:20:00+00:00',\n",
      "               ...\n",
      "               '2017-12-30 03:40:00+00:00', '2017-12-30 03:50:00+00:00',\n",
      "               '2017-12-30 04:00:00+00:00', '2017-12-30 19:50:00+00:00',\n",
      "               '2017-12-31 12:30:00+00:00', '2017-12-31 20:50:00+00:00',\n",
      "               '2017-12-31 21:00:00+00:00', '2017-12-31 23:30:00+00:00',\n",
      "               '2017-12-31 23:40:00+00:00', '2017-12-31 23:50:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='Timestamp', length=524, freq=None)\n",
      "Setting them to nan\n",
      "No occurrences found for Power.\n",
      "Initializing WT_06\n",
      "Timestamps where Wind is > 4.5 but Gen_speed is 0:\n",
      "DatetimeIndex(['2016-10-31 15:30:00+00:00', '2016-10-31 15:40:00+00:00',\n",
      "               '2016-10-31 15:50:00+00:00', '2016-10-31 16:00:00+00:00',\n",
      "               '2016-10-31 16:10:00+00:00', '2016-10-31 16:20:00+00:00',\n",
      "               '2016-10-31 16:30:00+00:00', '2016-11-02 11:10:00+00:00',\n",
      "               '2016-11-02 11:20:00+00:00', '2016-11-02 11:30:00+00:00',\n",
      "               ...\n",
      "               '2017-11-15 11:10:00+00:00', '2017-11-15 11:20:00+00:00',\n",
      "               '2017-11-15 11:50:00+00:00', '2017-11-15 12:00:00+00:00',\n",
      "               '2017-11-15 12:10:00+00:00', '2017-11-15 12:30:00+00:00',\n",
      "               '2017-11-15 13:00:00+00:00', '2017-11-15 13:30:00+00:00',\n",
      "               '2017-11-15 14:00:00+00:00', '2017-11-15 14:10:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='Timestamp', length=154, freq=None)\n",
      "Setting them to nan\n",
      "No occurrences found for Gen_speed_std.\n",
      "Timestamps where Wind is > 4.5 but Rotor_speed is 0:\n",
      "DatetimeIndex(['2016-02-08 14:50:00+00:00', '2016-02-08 15:00:00+00:00',\n",
      "               '2016-02-08 15:10:00+00:00', '2016-02-08 15:20:00+00:00',\n",
      "               '2016-02-21 08:20:00+00:00', '2016-02-21 08:30:00+00:00',\n",
      "               '2016-02-21 08:40:00+00:00', '2016-02-21 08:50:00+00:00',\n",
      "               '2016-02-21 09:00:00+00:00', '2016-02-21 09:10:00+00:00',\n",
      "               ...\n",
      "               '2017-12-18 14:00:00+00:00', '2017-12-18 14:10:00+00:00',\n",
      "               '2017-12-18 14:20:00+00:00', '2017-12-18 14:30:00+00:00',\n",
      "               '2017-12-18 14:40:00+00:00', '2017-12-18 14:50:00+00:00',\n",
      "               '2017-12-18 15:00:00+00:00', '2017-12-18 15:10:00+00:00',\n",
      "               '2017-12-18 15:20:00+00:00', '2017-12-18 15:30:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='Timestamp', length=798, freq=None)\n",
      "Setting them to nan\n",
      "Timestamps where Wind is > 4.5 but Rotor_speed_std is 0:\n",
      "DatetimeIndex(['2016-01-06 00:40:00+00:00', '2016-01-15 00:00:00+00:00',\n",
      "               '2016-01-15 00:10:00+00:00', '2016-01-24 09:50:00+00:00',\n",
      "               '2016-01-26 18:50:00+00:00', '2016-01-26 20:00:00+00:00',\n",
      "               '2016-02-01 00:50:00+00:00', '2016-02-01 22:10:00+00:00',\n",
      "               '2016-02-01 22:30:00+00:00', '2016-02-01 22:40:00+00:00',\n",
      "               ...\n",
      "               '2017-12-29 19:50:00+00:00', '2017-12-29 23:10:00+00:00',\n",
      "               '2017-12-29 23:20:00+00:00', '2017-12-29 23:40:00+00:00',\n",
      "               '2017-12-29 23:50:00+00:00', '2017-12-31 19:20:00+00:00',\n",
      "               '2017-12-31 19:30:00+00:00', '2017-12-31 20:50:00+00:00',\n",
      "               '2017-12-31 23:30:00+00:00', '2017-12-31 23:40:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='Timestamp', length=741, freq=None)\n",
      "Setting them to nan\n",
      "No occurrences found for Power.\n",
      "Initializing WT_07\n",
      "Timestamps where Wind is > 4.5 but Gen_speed is 0:\n",
      "DatetimeIndex(['2016-05-13 08:00:00+00:00', '2016-09-21 16:10:00+00:00',\n",
      "               '2016-09-21 16:20:00+00:00', '2016-09-21 16:30:00+00:00',\n",
      "               '2016-09-21 16:40:00+00:00', '2016-09-21 16:50:00+00:00',\n",
      "               '2016-10-01 11:20:00+00:00', '2016-10-01 12:10:00+00:00',\n",
      "               '2016-10-01 12:20:00+00:00', '2016-10-01 12:30:00+00:00',\n",
      "               ...\n",
      "               '2017-08-28 17:50:00+00:00', '2017-08-28 18:10:00+00:00',\n",
      "               '2017-08-28 18:20:00+00:00', '2017-08-28 18:30:00+00:00',\n",
      "               '2017-08-28 18:50:00+00:00', '2017-08-28 19:00:00+00:00',\n",
      "               '2017-08-28 19:10:00+00:00', '2017-08-31 13:30:00+00:00',\n",
      "               '2017-08-31 13:40:00+00:00', '2017-08-31 13:50:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='Timestamp', length=226, freq=None)\n",
      "Setting them to nan\n",
      "No occurrences found for Gen_speed_std.\n",
      "Timestamps where Wind is > 4.5 but Rotor_speed is 0:\n",
      "DatetimeIndex(['2016-01-12 22:30:00+00:00', '2016-01-12 22:40:00+00:00',\n",
      "               '2016-03-01 12:30:00+00:00', '2016-03-27 16:40:00+00:00',\n",
      "               '2016-03-27 17:00:00+00:00', '2016-03-27 18:10:00+00:00',\n",
      "               '2016-03-27 18:50:00+00:00', '2016-03-27 19:10:00+00:00',\n",
      "               '2016-07-14 15:50:00+00:00', '2016-07-14 16:00:00+00:00',\n",
      "               ...\n",
      "               '2017-11-11 16:30:00+00:00', '2017-11-11 16:40:00+00:00',\n",
      "               '2017-11-11 16:50:00+00:00', '2017-12-04 09:50:00+00:00',\n",
      "               '2017-12-15 11:50:00+00:00', '2017-12-15 12:00:00+00:00',\n",
      "               '2017-12-15 12:10:00+00:00', '2017-12-15 12:20:00+00:00',\n",
      "               '2017-12-15 12:30:00+00:00', '2017-12-19 17:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='Timestamp', length=1354, freq=None)\n",
      "Setting them to nan\n",
      "Timestamps where Wind is > 4.5 but Rotor_speed_std is 0:\n",
      "DatetimeIndex(['2016-01-06 01:00:00+00:00', '2016-01-15 03:50:00+00:00',\n",
      "               '2016-01-17 22:00:00+00:00', '2016-01-18 06:10:00+00:00',\n",
      "               '2016-01-26 19:50:00+00:00', '2016-01-31 01:50:00+00:00',\n",
      "               '2016-02-01 21:50:00+00:00', '2016-02-01 22:50:00+00:00',\n",
      "               '2016-02-02 05:30:00+00:00', '2016-02-02 08:20:00+00:00',\n",
      "               ...\n",
      "               '2017-12-29 19:30:00+00:00', '2017-12-29 19:40:00+00:00',\n",
      "               '2017-12-29 19:50:00+00:00', '2017-12-29 20:00:00+00:00',\n",
      "               '2017-12-29 21:40:00+00:00', '2017-12-29 22:40:00+00:00',\n",
      "               '2017-12-29 23:20:00+00:00', '2017-12-29 23:30:00+00:00',\n",
      "               '2017-12-29 23:40:00+00:00', '2017-12-30 07:00:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='Timestamp', length=504, freq=None)\n",
      "Setting them to nan\n",
      "No occurrences found for Power.\n",
      "Initializing WT_11\n",
      "Timestamps where Wind is > 4.5 but Gen_speed is 0:\n",
      "DatetimeIndex(['2016-03-27 10:50:00+00:00', '2016-09-22 12:40:00+00:00',\n",
      "               '2016-09-22 12:50:00+00:00', '2016-09-22 13:00:00+00:00',\n",
      "               '2016-09-22 13:10:00+00:00', '2016-09-22 13:20:00+00:00',\n",
      "               '2017-05-09 09:30:00+00:00', '2017-05-09 09:40:00+00:00',\n",
      "               '2017-05-09 09:50:00+00:00', '2017-05-09 10:00:00+00:00',\n",
      "               '2017-05-09 10:10:00+00:00', '2017-05-09 10:20:00+00:00',\n",
      "               '2017-05-09 10:40:00+00:00', '2017-05-09 13:50:00+00:00',\n",
      "               '2017-05-09 14:00:00+00:00', '2017-05-09 14:10:00+00:00',\n",
      "               '2017-05-09 14:20:00+00:00', '2017-05-09 14:30:00+00:00',\n",
      "               '2017-05-09 14:40:00+00:00', '2017-10-10 16:30:00+00:00',\n",
      "               '2017-10-10 17:00:00+00:00', '2017-10-10 17:10:00+00:00',\n",
      "               '2017-10-10 17:20:00+00:00', '2017-10-10 17:30:00+00:00',\n",
      "               '2017-10-10 17:40:00+00:00', '2017-10-10 17:50:00+00:00',\n",
      "               '2017-12-07 04:00:00+00:00', '2017-12-07 04:20:00+00:00',\n",
      "               '2017-12-07 04:40:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='Timestamp', freq=None)\n",
      "Setting them to nan\n",
      "No occurrences found for Gen_speed_std.\n",
      "Timestamps where Wind is > 4.5 but Rotor_speed is 0:\n",
      "DatetimeIndex(['2016-03-10 12:20:00+00:00', '2016-03-27 04:10:00+00:00',\n",
      "               '2016-03-27 04:20:00+00:00', '2016-03-27 04:30:00+00:00',\n",
      "               '2016-03-27 04:40:00+00:00', '2016-03-27 04:50:00+00:00',\n",
      "               '2016-03-27 05:00:00+00:00', '2016-03-27 05:10:00+00:00',\n",
      "               '2016-03-27 05:20:00+00:00', '2016-03-27 05:30:00+00:00',\n",
      "               ...\n",
      "               '2017-12-07 08:40:00+00:00', '2017-12-07 08:50:00+00:00',\n",
      "               '2017-12-07 09:00:00+00:00', '2017-12-07 09:10:00+00:00',\n",
      "               '2017-12-07 09:20:00+00:00', '2017-12-07 09:30:00+00:00',\n",
      "               '2017-12-07 09:40:00+00:00', '2017-12-11 06:10:00+00:00',\n",
      "               '2017-12-11 07:20:00+00:00', '2017-12-11 07:30:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='Timestamp', length=311, freq=None)\n",
      "Setting them to nan\n",
      "Timestamps where Wind is > 4.5 but Rotor_speed_std is 0:\n",
      "DatetimeIndex(['2016-01-06 20:20:00+00:00', '2016-01-07 23:30:00+00:00',\n",
      "               '2016-01-08 01:50:00+00:00', '2016-01-08 02:00:00+00:00',\n",
      "               '2016-01-08 02:10:00+00:00', '2016-01-13 00:30:00+00:00',\n",
      "               '2016-01-15 03:30:00+00:00', '2016-01-17 23:00:00+00:00',\n",
      "               '2016-01-18 05:10:00+00:00', '2016-01-18 05:20:00+00:00',\n",
      "               ...\n",
      "               '2017-12-26 19:40:00+00:00', '2017-12-26 19:50:00+00:00',\n",
      "               '2017-12-26 20:00:00+00:00', '2017-12-26 20:10:00+00:00',\n",
      "               '2017-12-26 20:20:00+00:00', '2017-12-26 20:30:00+00:00',\n",
      "               '2017-12-26 20:50:00+00:00', '2017-12-29 08:50:00+00:00',\n",
      "               '2017-12-29 09:20:00+00:00', '2017-12-30 06:10:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', name='Timestamp', length=844, freq=None)\n",
      "Setting them to nan\n",
      "No occurrences found for Power.\n",
      "(105261, 23)\n",
      "(105264, 23)\n",
      "(105264, 23)\n",
      "(105264, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_545999/669128751.py:243: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  pd.to_datetime(getattr(self,t).index,errors='ignore')\n",
      "/tmp/ipykernel_545999/669128751.py:243: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  pd.to_datetime(getattr(self,t).index,errors='ignore')\n",
      "/tmp/ipykernel_545999/669128751.py:243: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  pd.to_datetime(getattr(self,t).index,errors='ignore')\n",
      "/tmp/ipykernel_545999/669128751.py:243: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  pd.to_datetime(getattr(self,t).index,errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "farm_edp = data_farm(\n",
    "    name = \"EDP\", \n",
    "    cols = cols_edp, \n",
    "    list_turbine_name=list_names_edp,\n",
    "    DATA_PATH=DATA_PATH_EDP,\n",
    "    FAULT_LOG_PATH = FAULT_LOG_PATH_EDP,\n",
    "    rename = rename_edp, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_distributions(df): \n",
    "    cols = [\n",
    "            \"Wind_speed\",\n",
    "            \"Wind_speed_std\",\n",
    "            \"Wind_rel_dir\",\n",
    "            \"Amb_temp\",\n",
    "            \"Gen_speed\", \n",
    "            \"Gen_speed_std\",\n",
    "            \"Rotor_speed\", \n",
    "            \"Rotor_speed_std\",\n",
    "            \"Blade_pitch\",\n",
    "            \"Blade_pitch_std\",\n",
    "            \"Gen_phase_temp_1\",\n",
    "            \"Gen_phase_temp_2\",\n",
    "            \"Gen_phase_temp_3\",\n",
    "            \"Transf_temp_p1\",\n",
    "            \"Transf_temp_p2\",\n",
    "            \"Transf_temp_p3\",\n",
    "            \"Gen_bearing_temp_1\", \n",
    "            \"Gen_bearing_temp_2\", \n",
    "            \"Hyd_oil_temp\",\n",
    "            \"Gear_oil_temp\",\n",
    "            \"Gear_bear_temp\", \n",
    "            \"Nacelle_position\",\n",
    "            \"Power\"\n",
    "        ]\n",
    "    for col in cols:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        sns.histplot(df[col], kde=True, ax=ax[0], color='green')\n",
    "        sns.boxplot(x=df[col], ax=ax[1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Preparing data windows\n",
      "\n",
      "\n",
      "EDP\n",
      "Preparing turbine WT_01\n",
      "Preparing turbine WT_06\n",
      "Preparing turbine WT_07\n",
      "Preparing turbine WT_11\n"
     ]
    }
   ],
   "source": [
    "in_cols = [\n",
    "    \"Wind_speed\",\n",
    "    \"Wind_speed_std\",\n",
    "    \"Wind_rel_dir\",\n",
    "    \"Amb_temp\",\n",
    "    \"Gen_speed\", \n",
    "    \"Gen_speed_std\",\n",
    "    \"Rotor_speed\", \n",
    "    \"Rotor_speed_std\",\n",
    "    \"Blade_pitch\",\n",
    "    \"Blade_pitch_std\",\n",
    "    \"Gen_phase_temp_1\",\n",
    "    \"Gen_phase_temp_2\",\n",
    "    \"Gen_phase_temp_3\",\n",
    "    \"Transf_temp_p1\",\n",
    "    \"Transf_temp_p2\",\n",
    "    \"Transf_temp_p3\",\n",
    "    \"Gen_bearing_temp_1\", \n",
    "    \"Gen_bearing_temp_2\", \n",
    "    \"Hyd_oil_temp\",\n",
    "    \"Gear_oil_temp\",\n",
    "    \"Gear_bear_temp\", \n",
    "    \"Nacelle_position\",\n",
    "]\n",
    "out_cols = [\"Power\"]\n",
    "\n",
    "print(\"\\n\\n Preparing data windows\\n\")\n",
    "print(\"\\nEDP\")\n",
    "farm_edp.get_window_data(in_shift=24*6, in_cols=in_cols, out_cols=out_cols, PATH = r\"data_prep\", RESET = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
