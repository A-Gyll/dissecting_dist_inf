{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/gpfs/tardis/home/ujx4ab/ondemand/dissecting_dist_inf/WF_Data/EDP/EDP_Model_Testing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "print(os.getcwd())\n",
    "\n",
    "from EDP_Model_Testing.test_lstm import WindTurbineDataset, get_aggregate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splits(dataset, split_timestamp, batch_size=32):\n",
    "    if isinstance(split_timestamp, str):\n",
    "        split_timestamp = pd.Timestamp(split_timestamp)\n",
    "\n",
    "    indices = list(range(len(dataset)))\n",
    "    timestamps = dataset.timestamps\n",
    "\n",
    "    train_val_indices = [i for i, t in zip(indices, timestamps) if t < split_timestamp]\n",
    "    test_indices = [i for i, t in zip(indices, timestamps) if t >= split_timestamp]\n",
    "\n",
    "    test_dataset = Subset(dataset, test_indices)\n",
    "    train_val_dataset = Subset(dataset, train_val_indices)\n",
    "\n",
    "    return test_dataset, train_val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating data ...\n",
      "EDP_WT_01.csv\n",
      "EDP_WT_01_X.pt\n",
      "EDP_WT_01_timestamp.pkl\n",
      "EDP_WT_01_y.pt\n",
      "EDP_WT_06.csv\n",
      "EDP_WT_06_X.pt\n",
      "EDP_WT_06_timestamp.pkl\n",
      "EDP_WT_06_y.pt\n",
      "EDP_WT_07.csv\n",
      "EDP_WT_07_X.pt\n",
      "EDP_WT_07_timestamp.pkl\n",
      "EDP_WT_07_y.pt\n",
      "EDP_WT_11.csv\n",
      "EDP_WT_11_X.pt\n",
      "EDP_WT_11_timestamp.pkl\n",
      "EDP_WT_11_y.pt\n",
      "accumulated_timestamps.csv\n",
      "X_tensor shape: torch.Size([420477, 145, 22])\n",
      "y_tensor shape: torch.Size([420477, 1])\n",
      "Number of timestamps: 420477\n",
      "Aggregating data ...\n",
      "EDP_WT_01.csv\n",
      "EDP_WT_01_X.pt\n",
      "EDP_WT_01_timestamp.pkl\n",
      "EDP_WT_01_y.pt\n",
      "EDP_WT_06.csv\n",
      "EDP_WT_06_X.pt\n",
      "EDP_WT_06_timestamp.pkl\n",
      "EDP_WT_06_y.pt\n",
      "EDP_WT_07.csv\n",
      "EDP_WT_07_X.pt\n",
      "EDP_WT_07_timestamp.pkl\n",
      "EDP_WT_07_y.pt\n",
      "EDP_WT_11.csv\n",
      "EDP_WT_11_X.pt\n",
      "EDP_WT_11_timestamp.pkl\n",
      "EDP_WT_11_y.pt\n",
      "X_tensor shape: torch.Size([420477, 145, 22])\n",
      "y_tensor shape: torch.Size([420477, 1])\n",
      "Number of timestamps: 420477\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = \"/home/ujx4ab/ondemand/dissecting_dist_inf/WF_Data/EDP/EDP_Model_Testing/data_prep\"\n",
    "FAULTS_DATA_FOLDER = DATA_FOLDER + \"_faults_included\"\n",
    "\n",
    "X_tensor, y_tensor, timestamps_array = get_aggregate_data(DATA_FOLDER)\n",
    "\n",
    "faults_X_tensor, faults_y_tensor, faults_timestamps_array = get_aggregate_data(FAULTS_DATA_FOLDER)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2763],\n",
       "        [0.2761],\n",
       "        [0.2364],\n",
       "        ...,\n",
       "        [0.0954],\n",
       "        [0.1434],\n",
       "        [0.1499]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = WindTurbineDataset(\n",
    "    X=X_tensor,\n",
    "    y=y_tensor,\n",
    "    timestamps=timestamps_array\n",
    ")\n",
    "\n",
    "faults_full_dataset = WindTurbineDataset(\n",
    "    X=X_tensor,\n",
    "    y=y_tensor,\n",
    "    timestamps=timestamps_array\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are different.\n"
     ]
    }
   ],
   "source": [
    "if (X_tensor.shape != faults_X_tensor.shape or \n",
    "    y_tensor.shape != faults_y_tensor.shape or \n",
    "    timestamps_array.shape != faults_timestamps_array.shape):\n",
    "    print(\"Datasets have different shapes.\")\n",
    "else:\n",
    "    if (torch.equal(X_tensor, faults_X_tensor) and\n",
    "        torch.equal(y_tensor, faults_y_tensor) and\n",
    "        (timestamps_array == faults_timestamps_array).all()):\n",
    "        print(\"Datasets are identical.\")\n",
    "    else:\n",
    "        print(\"Datasets are different.\")\n",
    "if not (timestamps_array == faults_timestamps_array).all():\n",
    "    print(f\"Unique timestamps in DATA_FOLDER: {set(timestamps_1)}\")\n",
    "    print(f\"Unique timestamps in FAULTS_DATA_FOLDER: {set(timestamps_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_val_dataset = get_data_splits(full_dataset, split_timestamp=\"2017-06-01\")\n",
    "faults_test_dataset, _ = get_data_splits(faults_full_dataset, split_timestamp=\"2017-06-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(dataset, directory, set):\n",
    "    os.makedirs(directory, exist_ok=True) \n",
    "    \n",
    "    X_list = []  \n",
    "    y_list = [] \n",
    "    mask_list = []  \n",
    "    timestamps_list = []  \n",
    "\n",
    "    for data, y, mask, timestamp in dataset:\n",
    "        X_list.append(data.numpy()) \n",
    "        y_list.append(y)\n",
    "        mask_list.append(mask.numpy())  \n",
    "        timestamps_list.append(timestamp)\n",
    "\n",
    "    # Stack lists into tensors or NumPy arrays\n",
    "    X_array = np.stack(X_list)  # Shape: (num_samples, sequence_length, num_features)\n",
    "    y_array = np.stack(y_list)  # Shape: (num_samples, ...)\n",
    "    mask_array = np.stack(mask_list)  # Shape: (num_samples, ...)\n",
    "    timestamps_array = np.stack(timestamps_list)  # Shape: (num_samples, ...)\n",
    "    average_Bp_bin_values = X_array[:, :, -1].mean(axis=1)\n",
    "    average_power_values = y_array.mean(axis=1)\n",
    "    averages_for_indexing = np.stack((average_Bp_bin_values, average_power_values), axis=1)\n",
    "\n",
    "    bin_edges = np.linspace(0, 1, 6)\n",
    "    binned_Bp = np.digitize(averages_for_indexing[:, 0], bins=np.linspace(-.01, 1.01, 5), right=False) - 1\n",
    "    binned_power = np.digitize(averages_for_indexing[:, 1], bins=np.linspace(-.01, 1.01, 3), right=False) - 1\n",
    "    binned_feature_avgs = np.stack((binned_Bp, binned_power), axis=1)\n",
    "\n",
    "    # Save as .npy files\n",
    "    np.save(os.path.join(directory, f'{set}X.npy'), X_array)\n",
    "    np.save(os.path.join(directory, f'{set}y.npy'), y_array)\n",
    "    np.save(os.path.join(directory, f'{set}mask.npy'), mask_array)\n",
    "    np.save(os.path.join(directory, f'{set}timestamps.npy'), timestamps_array)\n",
    "    np.save(os.path.join(directory, f'{set}binned_feature_avgs.npy'), binned_feature_avgs)\n",
    "\n",
    "    print(f\"Data saved to {directory}\")\n",
    "    print(f\"X shape: {X_array.shape}\")\n",
    "    print(f\"y shape: {y_array.shape}\")\n",
    "    print(f\"mask shape: {mask_array.shape}\")\n",
    "    print(f\"timestamps shape: {timestamps_array.shape}\")\n",
    "    print(f\"averages for indexing: {binned_feature_avgs.shape}\")\n",
    "\n",
    "    return averages_for_indexing, binned_feature_avgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /home/ujx4ab/ondemand/dissecting_dist_inf/datasets/LSTM_WTs/\n",
      "X shape: (264921, 145, 22)\n",
      "y shape: (264921, 1)\n",
      "mask shape: (264921, 145)\n",
      "timestamps shape: (264921,)\n",
      "averages for indexing: (264921, 2)\n",
      "Data saved to /home/ujx4ab/ondemand/dissecting_dist_inf/datasets/LSTM_WTs/\n",
      "X shape: (105145, 145, 22)\n",
      "y shape: (105145, 1)\n",
      "mask shape: (105145, 145)\n",
      "timestamps shape: (105145,)\n",
      "averages for indexing: (105145, 2)\n"
     ]
    }
   ],
   "source": [
    "averages_for_indexing1, binned_feature_avgs1 = save_data(train_val_dataset, directory=\"/home/ujx4ab/ondemand/dissecting_dist_inf/datasets/LSTM_WTs/\", set=\"train_val_dataset_\")\n",
    "averages_for_indexing2, binned_feature_avgs2 = save_data(faults_test_dataset, directory=\"/home/ujx4ab/ondemand/dissecting_dist_inf/datasets/LSTM_WTs/\", set=\"faults_test_dataset_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power\n",
      "0.000000    74093\n",
      "0.996615       62\n",
      "0.996719       57\n",
      "0.996725       55\n",
      "0.996743       52\n",
      "            ...  \n",
      "0.114926        1\n",
      "0.086484        1\n",
      "0.076630        1\n",
      "0.072542        1\n",
      "0.010734        1\n",
      "Name: count, Length: 166214, dtype: int64\n",
      "Power\n",
      "0    201327\n",
      "1     63594\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "this_df1 = pd.DataFrame(averages_for_indexing1, columns=['Bp_bin', 'Power'])\n",
    "this_df2 = pd.DataFrame(binned_feature_avgs1, columns=['Bp_bin', 'Power'])\n",
    "\n",
    "print(this_df1['Power'].value_counts())\n",
    "print(this_df2['Power'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9655172 , 0.18498261],\n",
       "       [0.9724138 , 0.15083884],\n",
       "       [0.9724138 , 0.21377672],\n",
       "       ...,\n",
       "       [0.6275862 , 0.0954418 ],\n",
       "       [0.63448274, 0.14342895],\n",
       "       [0.6413793 , 0.14989664]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averages_for_indexing2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
