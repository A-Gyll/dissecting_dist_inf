{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os, json\n",
    "from tqdm import tqdm\n",
    "import torch as ch\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import implem_utils\n",
    "from scorecam import ScoreCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "def get_input_tensors(img):\n",
    "    # unsqeeze converts single image to batch of 1\n",
    "    return transform(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(path):\n",
    "    model = utils.FaceModel(512,\n",
    "                            train_feat=True,\n",
    "                            weight_init=None,\n",
    "                            hidden=[64, 16]).cuda()\n",
    "    model = nn.DataParallel(model)\n",
    "    model.load_state_dict(ch.load(path), strict=False)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = utils.Celeb()\n",
    "ds = constants.get_dataset()\n",
    "\n",
    "attrs = constants.attr_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_255_image(z):\n",
    "    z_ = z.numpy().transpose(1, 2, 0)\n",
    "    z_ = 0.5 * z_ + 0.5\n",
    "    return (z_ * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(z):\n",
    "    plt.imshow(raw_255_image(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(model, images):\n",
    "    batch = ch.stack(tuple(transform(i) for i in images), dim=0)\n",
    "    \n",
    "    logits = model(batch.cuda()).detach()\n",
    "    probs = ch.sigmoid(logits)\n",
    "    probs = ch.stack([1 - probs[:, 0], probs[:, 0]], 1)\n",
    "    return probs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model):\n",
    "    constants = utils.Celeb()\n",
    "    ds = constants.get_dataset()\n",
    "    td = utils.CelebACustomBinary(\n",
    "        \"/p/adversarialml/as9rw/datasets/celeba_raw_crop/splits/70_30/all/split_2/test\",\n",
    "        transform=transform)\n",
    "    cropped_dataloader = DataLoader(td,\n",
    "                                batch_size=15,\n",
    "                                shuffle=True)\n",
    "    \n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "    \n",
    "    def model_batch_predict(x):\n",
    "        return batch_predict(model, x)\n",
    "\n",
    "    scores = []\n",
    "    labels = []\n",
    "\n",
    "    for i, (x, y) in tqdm(enumerate(cropped_dataloader)):\n",
    "        x_raw = [raw_255_image(x_) for x_ in x]\n",
    "        labels.append(y.numpy())\n",
    "        \n",
    "        if i < 1:\n",
    "            continue\n",
    "    \n",
    "        for img_t in x_raw:\n",
    "            explanation = explainer.explain_instance(img_t,\n",
    "                                                     model_batch_predict, # classification function\n",
    "                                                     top_labels=1, \n",
    "                                                     hide_color=0, \n",
    "                                                     num_samples=2000)\n",
    "    \n",
    "            temp, mask = explanation.get_image_and_mask(explanation.top_labels[0],\n",
    "                                                        positive_only=True,\n",
    "                                                        num_features=5,\n",
    "                                                        hide_rest=False)\n",
    "    \n",
    "            img_boundry1 = mark_boundaries(temp/255.0, mask)\n",
    "            plt.imshow(img_boundry1)\n",
    "            return (temp, mask)\n",
    "            \n",
    "            temp_pos = temp * (np.expand_dims(mask, 2))\n",
    "            temp_neg = temp * (1 - np.expand_dims(mask, 2))\n",
    "            test_pred = model_batch_predict([temp_pos.astype(np.uint8), temp_neg.astype(np.uint8)])\n",
    "            scores.append(test_pred[:, 1])\n",
    "        \n",
    "        if i == 3: break\n",
    "    \n",
    "    return np.stack(scores, 0), np.concatenate(labels, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\"/u/as9rw/work/fnb/implems/celeba_models_split/70_30/split_1/all/augment_vggface/20_0.9151053864168618.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = get_scores(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ = ch.unsqueeze(ch.from_numpy(temp / 255.), 0)\n",
    "temp_ = temp_.permute(0, 3, 1, 2).float().cuda()\n",
    "score_cam = ScoreCam(model, target_layer=11)\n",
    "# Generate cam mask\n",
    "cam = score_cam.generate_cam(temp_, target_class=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as mpl_color_map\n",
    "\n",
    "# color_map = mpl_color_map.get_cmap('hsv')\n",
    "# no_trans_heatmap = color_map(cam)\n",
    "tempo = temp.copy()\n",
    "\n",
    "cam_ = (cam >= 0.4)\n",
    "\n",
    "for i in range(3):\n",
    "    tempo[:, :, i] = (cam_ * tempo[:, :, i]).astype(np.uint8)\n",
    "\n",
    "plt.imshow(tempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_auto_complete(model, image, mask, target, lr):\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    image_ = image/255\n",
    "    x_opt = ch.from_numpy(image_).cuda()\n",
    "    x_opt = x_opt.permute(2, 0, 1).float()\n",
    "\n",
    "    mask_ = ch.from_numpy(1 - mask).cuda()\n",
    "    mask_ = ch.unsqueeze(ch.unsqueeze(mask_, 0), 0)\n",
    "    mask_ = mask_.repeat(1, 3, 1, 1)\n",
    "    \n",
    "    gt = ch.tensor([[target]]).cuda()\n",
    "    \n",
    "    inp = ch.unsqueeze((x_opt - 0.5)/0.5, 0).clone() * (1 - mask_)\n",
    "#     inp += (mask_) * 0.5\n",
    "    \n",
    "    # Fill balck with average color of image?\n",
    "    inp = Variable(inp, requires_grad=True)\n",
    "    \n",
    "    iterator = tqdm(range(50))\n",
    "    for i in iterator:\n",
    "        logit = model(inp)\n",
    "        \n",
    "        loss = loss_fn(logit, gt)\n",
    "        loss.backward(ch.ones_like(loss), retain_graph=True)\n",
    "        \n",
    "        # Back-flow of gradient\n",
    "        # But only where mask permits it\n",
    "        inp.data -= (lr * inp.grad * mask_)\n",
    "        \n",
    "        # Clamp back image into (-0.5, 0.5)\n",
    "        inp.data = ch.clamp(inp.data, -0.5, 0.5)\n",
    "        \n",
    "        iterator.set_description(\"Loss: %.4f\" % loss.item())\n",
    "    \n",
    "    return inp.detach().cpu().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_autofill = mask_auto_complete(model, temp, cam_ * 0,\n",
    "                                   target=1.,\n",
    "                                   lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(temp_autofill[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_drop(m, blr=0.25):\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5), (0.5))])\n",
    "    td = utils.CelebACustomBinary(\n",
    "        \"/p/adversarialml/as9rw/datasets/celeba_raw_crop/splits/70_30/all/split_2/test\",\n",
    "        transform=transform)\n",
    "    cropped_dataloader = DataLoader(td,\n",
    "                                batch_size=75,\n",
    "                                shuffle=True)\n",
    "    correct, total = 0, 0\n",
    "    for (x, y) in tqdm(cropped_dataloader):\n",
    "        # Blank our lower blr% of image\n",
    "        x[:, :, :, -int(blr * x.shape[3]):] = -0.5\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        preds = (model(x)[:, 0] >= 0)\n",
    "        correct += ch.sum(preds == y[:, attrs.index(\"Smiling\")]).sum().cpu().item()\n",
    "        total += y.shape[0]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:23<00:00,  3.43it/s]\n",
      "100%|██████████| 80/80 [00:22<00:00,  3.54it/s]\n",
      "100%|██████████| 80/80 [00:22<00:00,  3.51it/s]\n",
      "100%|██████████| 80/80 [00:24<00:00,  3.30it/s]\n",
      "100%|██████████| 80/80 [00:23<00:00,  3.43it/s]\n",
      "100%|██████████| 80/80 [00:23<00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8966212808875441, 0.8840141200201714, 0.8347621448983022, 0.7528996469994957, 0.4989073793914944, 0.49840309295679946]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ratios = [0.25, 0.3, 0.4, 0.5, 0.7, 0.9]\n",
    "perfs = []\n",
    "for ratio in ratios:\n",
    "    perfs.append(perf_drop(model, blr=ratio))\n",
    "\n",
    "print(perfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:24<00:00,  3.30it/s]\n",
      "100%|██████████| 80/80 [00:23<00:00,  3.46it/s]\n",
      "100%|██████████| 80/80 [00:23<00:00,  3.40it/s]\n",
      "100%|██████████| 80/80 [00:23<00:00,  3.34it/s]\n",
      "100%|██████████| 80/80 [00:23<00:00,  3.42it/s]\n",
      "100%|██████████| 80/80 [00:22<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9088922507984535, 0.9009917633215666, 0.8473693057656749, 0.7406286770885863, 0.4987392839132627, 0.49840309295679946]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = get_model(\"/u/as9rw/work/fnb/implems/celeba_models_split/70_30/split_1/male/augment_vggface/20_0.9246347941567065.pth\")\n",
    "\n",
    "ratios = [0.25, 0.3, 0.4, 0.5, 0.7, 0.9]\n",
    "perfs = []\n",
    "for ratio in ratios:\n",
    "    perfs.append(perf_drop(model, blr=ratio))\n",
    "\n",
    "print(perfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_autofill = mask_auto_complete(model, temp, 1 - mask,\n",
    "                                   target=1.,\n",
    "                                   lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\"/u/as9rw/work/fnb/implems/celeba_models_split/70_30/split_1/all/augment_vggface/10_0.928498243559719.pth\")\n",
    "_ = get_scores(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\"/u/as9rw/work/fnb/implems/celeba_models_split/70_30/split_1/all/augment_vggface/4_0.9207406323185011.pth\")\n",
    "get_scores(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(\"/u/as9rw/work/fnb/implems/celeba_models_split/70_30/split_1/male/augment_vggface/20_0.9246347941567065.pth\")\n",
    "get_scores(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_male = np.nonzero(labels[:, attrs.index(\"Male\")])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_female = np.nonzero(1 - labels[:, attrs.index(\"Male\")])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores[where_male, 0] - scores[where_male, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores[where_female, 0] - scores[where_female, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "phd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
